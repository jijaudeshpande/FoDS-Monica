---
title: "final"
author: "Abrar El Dada,Jijau Deshpande"
date: "6/25/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

# insalling needed packages 
```{r}
#install.packages("pacman", repos = "http://cran.us.r-project.org")
#install.packages("data.table")
library(pacman)
p_load(RColorBrewer, # color pallets
       ggplot2,  # reportable graphs 
       cowplot,# arranges ggplot graphs nicely
       glmnet,
       pROC,
       stargazer,
       caret,
       rpart)


library(data.table)
outlierReplace = function(dataframe, cols, rows, newValue = NA) {
    if (any(rows)) {
        set(dataframe, rows, cols, newValue)
    }
} # needed to replace the outliers with the mean value 



```
# reading the data
```{r}
monica_new <- read.csv("monica.csv", stringsAsFactors = T) #chnaged the xls to csv
```

# checking for missing values
```{r}
anyNA(monica_new)

```
there are no missing values !

##outcome
# Renaming values in column outcome to 0 and 1
```{r}
monica_new$outcome <- ifelse(monica_new$outcome == "dead", 0,1)

```



# cheking for outliers 

#we have only two contunous variables which are age and yronset. so we check these two for possible outliers. (using boxplot) 

## Outliers in age

```{r}
boxplot(monica_new$age)
boxplot(monica_new$age, plot=FALSE)$out

median(monica_new$age)
mean(monica_new$age)

# since we only have 89 outlier, which is almost 1% from the data. We decided impute the outliers with mean . the mean value and the median value havn't changed. new median : 61. new mean:60.02089. old mean: 59.41998. old median: 61. We need to sownload the package table.table to be able to do the replacment. 

outlierReplace(monica_new, "age", which(monica_new$age < 
    41), mean(monica_new$age))
boxplot(monica_new$age)

```


## checking the outliers in yronset: 

```{r}

boxplot(monica_new$yronset)
boxplot(monica_new$yronset, plot=FALSE)$out

 
```
in yronset there are no outliers


# skewness: (not done yet )

## age 
```{r}
## age 

age_density <- density(monica_new$age)
plot(age_density, main="Density of age")
polygon(age_density, col="red", border="red")
#negative skewd , skewd toward lef because the skew valus is negative

#install.packages("moments",  # for calculating skeweness
                 #repos = "http://cran.us.r-project.org") 

library(moments) 




skewness((monica_new$age)) 
# the skewness value is -0.790908 
skewness((monica_new$age +0.01))   #  even if used the log to treat it, it wont make a noticable diffeterent (-1.0277277)
# so we square it and use log to treat it .
monica_new$age_sqr_ln<-(log(monica_new$age))^2



# here we find the two plots for the data and we notice that using the log didnt make a big different
par(mfrow = c(1,3))
plot(density(monica_new$age),
     main     = "Density Plot of age",
     col      = "royalblue4", 
     cex.main = 0.7)

plot(density(log(monica_new$age_sqr_ln+0.01)),
     main = "Density Plot of age log",
     col  = "royalblue4", 
     cex.main = 0.7)
plot(density(log(monica_new$age_sqr_ln+0.001)),
     main = "Density Plot of age log",
     col  = "royalblue4", 
     cex.main = 0.7)


#Conclusion: as the skewness is nearest to 0 when we don't treat the variable with log or square i will use the variable as it is




```


##yronset

```{r}

#*************Make it categorical!!!!*****************
yronset_density <- density(monica_new$yronset)
plot(yronset_density, main="Density of yronset")
polygon(yronset_density, col="blue", border="blue")


skewness((monica_new$yronset))
# we notice that the data looks ok and we don't think that it's skewed.

par(mfrow = c(1,2))
plot(density(monica_new$yronset),
     main     = "Density Plot of yronset",
     col      = "royalblue4", 
     cex.main = 0.7)

plot(density(log(monica_new$yronset+0.01)),
     main = "Density Plot of yronset log",
     col  = "royalblue4", 
     cex.main = 0.7)

#we preprocessed the variable yronset but as it  doesn't contribute to the varible outcome, we choose to not use the variable in building models and predicting.
 
```


# loading necessary packages and user functions

```{r}
library(pacman)
p_load(RColorBrewer, # color pallets
       ggplot2,  # reportable graphs 
       cowplot,   # arranges ggplot graphs nicely
       stargazer,
       MASS) 
Accuracy <- function(pred, real, threshold = 0.5){
  predClass <-  ifelse(pred > threshold, 1, 0)
  acc <- sum(predClass == real) / length(real)
  return(acc)
}# paremeters of a specified distribution
#lm([target variable] ~ [predictor variables], data = [data source])
#lm([] ~ [predictor variables], data = [data source])
#lm1 <- lm(monica_new$outcome ~ 1 + monica_new$age, data = monica_new)
#lm2 <- lm(outcome ~ age + yronset , 
          #data = monica_new)

```

#Logistic regression wihtout regularization and without splitting data

```{r}
log1 <- glm(outcome ~ . - yronset -angina - smstat,
            data = monica_new,
            family = binomial(link = "logit"))

stargazer(log1, type = "text")


pred.log1 <- predict(log1, newdata = monica_new, type = "response")

#Evaluate
pred.class.log1 <- ifelse(pred.log1 > 0.5, 1, 0)
table(pred.class.log1)

# Actual values of outcome
table(monica_new$outcome)

#Accuracy
sum(monica_new$outcome == pred.class.log1)/length(pred.class.log1)

# Missclassification error
(1- sum(monica_new$outcome == pred.class.log1)/length(pred.class.log1))

#Brier score
(RMSE.log1 <- sqrt(mean((monica_new$outcome - pred.log1)^2)))

# logit
auc(monica_new$outcome, pred.log1)
```

#Logistic regression with regularization


#Splitting the data to Avoid overfitting


```{r}

set.seed(777)
train.Index <-  sample(1:nrow(monica_new), round(0.7*nrow(monica_new)), replace = F)
# creating the train and test sets using train.Index 
monica_new.train <- monica_new[train.Index,]
monica_new.test  <- monica_new[-train.Index,]
  
# creating x and y for model training
# y - a target vector
y.train <- monica_new.train$outcome
y.test  <- monica_new.test$outcome

# X - a matrix with features/predictors 
features <- c('age', 'sex', 'hosp', 'diabetes','smstat', #'yronset' is not a useful varibale, #also ommitting premi
'highbp','hichol', 'angina', 'stroke')

model.matrix( ~ ., data = monica_new.train[, features])
X.train <- model.matrix( ~ . -1, data = monica_new.train[, features])
X.test  <- model.matrix( ~ . -1, data = monica_new.test[, features])

```


#Ridge regression

```{r}
log_r1 <- glmnet(X.train, y.train, alpha = 0, family="binomial")

summary(log_r1)

plot(log_r1, xvar = "lambda")
legend("bottomright", lwd = 1, col = 1:16, legend = colnames(X.test), cex = .3)


plot(y = log_r1$dev.ratio, 
     x = log_r1$lambda,
     xlab = "lambda",
     ylab = "R-squared")

log_r1$lambda
options(scipen = 999)
log_r1$beta[, 1]  
log_r1$beta[, 100]



set.seed(77)
log_r1_cv <- cv.glmnet(X.train, y.train, alpha = 0, type.measure = "class", 
                       lambda = 10^seq(-5, 1, length.out = 100), family="binomial", nfolds = 10)
#class : the missclassification error(opposite of accuracy)

log_r1_cv$lambda

log_r1_cv$cvm 

log_r1_cv$lambda.min# this lambda has the least classification error


coef(log_r1_cv, s = "lambda.min")

y.predlog_r1 <-  predict(log_r1,    newx = X.test, type = "response", s = log_r1_cv$lambda.min)
y.pred_r1_cv <-  predict(log_r1_cv, newx = X.test, type = "response", s = "lambda.min")

#Accuracy , higher the better
Accuracy(pred = y.pred_r1_cv, real = y.test)


# missclassification error
(1-Accuracy(pred = y.pred_r1_cv, real = y.test))

#Brier Score(not done)
(RMSE.log1 <- sqrt(mean((y.test - y.predlog_r1)^2)))

# AUC ridge
auc(y.test, y.predlog_r1)

```



#LASSO REGRESSION
```{r}

# Although by default glmnet calls for 100 values of lambda the program stops early if 
# `%dev% does not change sufficently from one lambda to the next 
# (typically near the end of the path.)
log_l1 <- glmnet(X.train, y.train, alpha = 1, family="binomial")

plot(log_l1, xvar = "lambda") # 
legend("bottomright", lwd = 1, col = 1:10, legend = colnames(X.train), cex = .4)

plot(y = log_l1$dev.ratio, 
     x = log_l1$lambda,
     xlab = "lambda",
     ylab = "R-squared")

log_l1$lambda
log_l1$beta[, 1]   # highest lambda
log_l1$beta[, 76] # lowest lambda

# selecting the optimal lambda
set.seed(77)
log_l1_cv <- cv.glmnet(X.train, y.train, alpha = 1, type.measure = "class", 
                       lambda = 10^seq(-5, 1, length.out = 100), family="binomial", nfolds = 10)
# log_l1_cv$lambda
# log_l1_cv$cvm  # misclassification error

log_l1_cv$lambda.min     # lambda resulting in the lowest misclassification error
which.min(log_l1_cv$cvm) # index of that lambda

y.predlog_l1 <-  predict(log_l1, newx = X.test, type = "response", s = log_l1_cv$lambda.min)

#Accuracy , higher the better
Accuracy(pred = y.predlog_l1, real = y.test)

# Missclassification error
(1-Accuracy(pred = y.predlog_l1, real = y.test))

## Brier Score(not yet done) 
(RMSE.log1 <- sqrt(mean((y.test - y.predlog_l1)^2)))

#AUC score
auc(y.test, y.predlog_l1)


```


#Decision Tress
```{r}
set.seed(7)
train.Index <- caret::createDataPartition(monica_new$outcome, p = 0.7, list = F)
monica_new.train <- monica_new[ train.Index,]
monica_new.test  <- monica_new[-train.Index,]

# features to be used for model training   
features <- c('outcome','age', 'hosp', 'sex','highbp','hichol', 'angina', 'stroke')#diabetes and smstat omitted

# ----- Fitting a model ------ 
# Training classification decision tree
dt <- rpart(outcome ~ . , 
            data = monica_new.train[,features], 
            method = "class", 
            parms = list(split = "information"),  # the splitting index 
            model = T) 

# ----- Deriving Predictions ------ 
# Predicting the instance of dieing
# first column  - probability of 0 for each observation
# second column - probability of 1
pred.dt <- predict(dt, newdata = monica_new.test, type = "prob")[, 2]


# ----- Evaluating Prediction Quality -----
# Calculate performance with AUC and RMSE
auc(monica_new.test$outcome, pred.dt)
( rmse <- sqrt(mean((monica_new.test$outcome - pred.dt)^2)) )
Accuracy(pred=pred.dt, real=monica_new.test$outcome)

# Naive Classifier(dont know what it is yet)
baseline_probability <- sum(monica_new.train$outcome == 1)/nrow(monica_new.train)
pred.baseline <- rep(baseline_probability, nrow(monica_new.test))

auc(monica_new.test$outcome, pred.baseline)
( rmse <- sqrt(mean((monica_new.test$outcome - pred.baseline)^2)) )
Accuracy(pred=pred.baseline, real=monica_new.test$outcome)

```


jh ghgjg hjg jhgjhg hjg 





